{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0cd5fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (25.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (4.55.2)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting datasets[audio]\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from datasets[audio]) (21.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets[audio])\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from datasets[audio]) (2.2.3)\n",
      "Collecting xxhash (from datasets[audio])\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets[audio])\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting soundfile>=0.12.1 (from datasets[audio])\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "INFO: pip is looking at multiple versions of datasets[audio] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting datasets[audio]\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting librosa (from datasets[audio])\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting soxr>=0.4.0 (from datasets[audio])\n",
      "  Downloading soxr-0.5.0.post1-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio])\n",
      "  Downloading aiohttp-3.12.15-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from accelerate) (2.8.0)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio])\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio])\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (24.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio])\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio])\n",
      "  Downloading multidict-6.6.4-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio])\n",
      "  Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio])\n",
      "  Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl.metadata (76 kB)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from requests->transformers) (2025.7.14)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from soundfile>=0.12.1->datasets[audio]) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (2.21)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Collecting audioread>=2.1.9 (from librosa->datasets[audio])\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting numba>=0.51.0 (from librosa->datasets[audio])\n",
      "  Downloading numba-0.61.2-cp311-cp311-win_amd64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from librosa->datasets[audio]) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from librosa->datasets[audio]) (1.7.0)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from librosa->datasets[audio]) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from librosa->datasets[audio]) (5.1.1)\n",
      "Collecting pooch>=1.1 (from librosa->datasets[audio])\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting lazy_loader>=0.1 (from librosa->datasets[audio])\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa->datasets[audio])\n",
      "  Downloading msgpack-1.1.1-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.0->librosa->datasets[audio])\n",
      "  Downloading llvmlite-0.44.0-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-2.2.6-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from pooch>=1.1->librosa->datasets[audio]) (4.3.7)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from scikit-learn>=1.1.0->librosa->datasets[audio]) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from pandas->datasets[audio]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from pandas->datasets[audio]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from pandas->datasets[audio]) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\mlenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets[audio]) (1.17.0)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading accelerate-1.10.0-py3-none-any.whl (374 kB)\n",
      "Downloading aiohttp-3.12.15-cp311-cp311-win_amd64.whl (453 kB)\n",
      "Downloading multidict-6.6.4-cp311-cp311-win_amd64.whl (46 kB)\n",
      "Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl (86 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl (41 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 12.0 MB/s  0:00:00\n",
      "Downloading soxr-0.5.0.post1-cp311-cp311-win_amd64.whl (166 kB)\n",
      "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.1-cp311-cp311-win_amd64.whl (72 kB)\n",
      "Downloading numba-0.61.2-cp311-cp311-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.8/2.8 MB 18.2 MB/s  0:00:00\n",
      "Downloading llvmlite-0.44.0-cp311-cp311-win_amd64.whl (30.3 MB)\n",
      "   ---------------------------------------- 0.0/30.3 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 4.7/30.3 MB 23.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 9.7/30.3 MB 23.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 13.4/30.3 MB 21.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 16.8/30.3 MB 20.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 21.5/30.3 MB 20.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 26.0/30.3 MB 20.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  30.1/30.3 MB 20.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 30.3/30.3 MB 19.4 MB/s  0:00:01\n",
      "Downloading numpy-2.2.6-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 4.5/12.9 MB 22.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 18.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.4/12.9 MB 15.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/12.9 MB 15.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 15.0 MB/s  0:00:00\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, propcache, numpy, multidict, msgpack, llvmlite, lazy_loader, fsspec, frozenlist, dill, audioread, aiohappyeyeballs, yarl, soxr, soundfile, pooch, numba, multiprocess, aiosignal, aiohttp, accelerate, librosa, datasets\n",
      "\n",
      "  Attempting uninstall: numpy\n",
      "\n",
      "    Found existing installation: numpy 2.3.1\n",
      "\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "    Uninstalling numpy-2.3.1:\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "      Successfully uninstalled numpy-2.3.1\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   --- ------------------------------------  2/23 [numpy]\n",
      "   ----- ----------------------------------  3/23 [multidict]\n",
      "   -------- -------------------------------  5/23 [llvmlite]\n",
      "   -------- -------------------------------  5/23 [llvmlite]\n",
      "   -------- -------------------------------  5/23 [llvmlite]\n",
      "   -------- -------------------------------  5/23 [llvmlite]\n",
      "   -------- -------------------------------  5/23 [llvmlite]\n",
      "  Attempting uninstall: fsspec\n",
      "   -------- -------------------------------  5/23 [llvmlite]\n",
      "    Found existing installation: fsspec 2025.7.0\n",
      "   -------- -------------------------------  5/23 [llvmlite]\n",
      "    Uninstalling fsspec-2025.7.0:\n",
      "   -------- -------------------------------  5/23 [llvmlite]\n",
      "   ------------ ---------------------------  7/23 [fsspec]\n",
      "      Successfully uninstalled fsspec-2025.7.0\n",
      "   ------------ ---------------------------  7/23 [fsspec]\n",
      "   ------------ ---------------------------  7/23 [fsspec]\n",
      "   ------------ ---------------------------  7/23 [fsspec]\n",
      "   ------------ ---------------------------  7/23 [fsspec]\n",
      "   --------------- ------------------------  9/23 [dill]\n",
      "   --------------- ------------------------  9/23 [dill]\n",
      "   ----------------- ---------------------- 10/23 [audioread]\n",
      "   ------------------------ --------------- 14/23 [soundfile]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   --------------------------- ------------ 16/23 [numba]\n",
      "   ----------------------------- ---------- 17/23 [multiprocess]\n",
      "   ----------------------------- ---------- 17/23 [multiprocess]\n",
      "   --------------------------------- ------ 19/23 [aiohttp]\n",
      "   --------------------------------- ------ 19/23 [aiohttp]\n",
      "   ---------------------------------- ----- 20/23 [accelerate]\n",
      "   ---------------------------------- ----- 20/23 [accelerate]\n",
      "   ---------------------------------- ----- 20/23 [accelerate]\n",
      "   ---------------------------------- ----- 20/23 [accelerate]\n",
      "   ------------------------------------ --- 21/23 [librosa]\n",
      "   ------------------------------------ --- 21/23 [librosa]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   ---------------------------------------- 23/23 [datasets]\n",
      "\n",
      "Successfully installed accelerate-1.10.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 audioread-3.0.1 datasets-3.6.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.44.0 msgpack-1.1.1 multidict-6.6.4 multiprocess-0.70.16 numba-0.61.2 numpy-2.2.6 pooch-1.8.2 propcache-0.3.2 soundfile-0.13.1 soxr-0.5.0.post1 xxhash-3.5.0 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --upgrade transformers datasets[audio] accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b4e6db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + r\"C:\\Users\\user\\Desktop\\KSM\\Tools\\ffmpeg-2025-08-18-git-0226b6fb2c-full_build\\bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15470924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597db1136b2f40fab7f08e294afc6daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\mlenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--openai--whisper-large-v3-turbo. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01856fd51a546d98e1b4dbe35962d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.62G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7177386553420ebba584712125632d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a3b4993eae48ce935a7b8e2d361c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a56659805414917b86fbecfd1348ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505d5505ddc243d699b97c690767a7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2172996ccf35468ab26af61d3447de59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afebfe963c44ed6bf3466db6327ba0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfacbc03d9d4bd19693761b272c32c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2816808e261b4377a0f06ae91e0acf99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9396bd47a3e40eb93b3ba1188dc092f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype = torch_dtype, low_cpu_mem_usage=True, \n",
    "    use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11afa757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Using `chunk_length_s` is very experimental with seq2seq models. The results will not necessarily be entirely accurate and will have caveats. More information: https://github.com/huggingface/transformers/pull/20104. Ignore this warning with pipeline(..., ignore_warning=True). To use Whisper for long-form transcription, use rather the model's `generate` method directly as the model relies on it's own chunking mechanism (cf. Whisper original paper, section 3.8. Long-form Transcription).\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model = model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device = device,\n",
    "    return_timestamps=True,\n",
    "    chunk_length_s = 10,\n",
    "    stride_length_s = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb087c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \" 탑인 한국 힙합 제가 생각할 때 어준간한 거 같아요 길을 못 찾고 있는 거 같아요 대중성으로나 아니면 음악성으로나 못 찾는 것 같아요 길을 제가 슈퍼 4K에 나온 이유는 제 길을 한번 발산해서 한국에서 힙합도 많이 발전할 수 있게 기여했으면 좋겠습니다. 좀 됐어요? 네. 해보시죠. 체크! 체크! I'm the Korean Thakura's hip-hop home, CHECK! CHECK! I'm not going to do that. I'm not going to do it. I'm not going to do it. I'm not going to do it. I'm not going to do it. I'm not going to do it. I'm not going to do it. I'm not going to do it. I'm not going to do it. I'm not going to do it. uh 아 어디 언어예요? 네? 암원같기도 하고 어디 언어예요? 네? 앙원같기도 하고 어디 언어예요? 그냥 공무집이에요 가사는 없는거고 가사가 있는거에요 가사가 있어요? 풀어줘 볼 수 있어요? 천천히요 천천히 완전 느리게 해보세요 한국어 탁클라스 힙합 모범 너블라스 페이블라스 케블라스 구조스폴 danger스 난 비틀 비틀 제껴 보니 비틀 비틀 제껴 보니 비틀 비틀 제껴 보니 비틀 비틀 제껴 보니 비틀 비틀 제껴 보니 비틀 비틀 제껴 보니 비틀 비틀 제껴 보니 비틀 비틀 제껴 보니 비틀 비틀 제껴 보니 비틀 비틀 제껴 보니 비틀 비틀 제껴 보니 비틀 비틀 제껴 보니 비틀 비틀 제껴 보니 비틀 비틀 제껴 보니 비틀 비틀 비틀 제껴 보니 한글자막 제공 및 자막 제공 및 협조해 주신 모든 분들께 진심으로 감사드립니다. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. 그러면 잡초마탈파우스 플리지 피해소 하하하하 아니 말이 이렇게 있어? 아 그니까 그 말을 뭐 이러면서 해가지고 잘 안 들리는 거죠 지금? 아 말이 있었다는 게 더 웃겨 가산이 있죠? 이야... 약간 경매장에 온 것 같기도 하고 불합격 저도 불합격 저도 불합격 드리겠습니다\", 'chunks': [{'timestamp': (0.0, 2.0), 'text': ' 탑인'}, {'timestamp': (7.0, 8.0), 'text': ' 한국 힙합 제가 생각할 때'}, {'timestamp': (8.0, 10.0), 'text': ' 어준간한 거 같아요'}, {'timestamp': (10.0, 11.0), 'text': ' 길을 못 찾고 있는 거 같아요'}, {'timestamp': (11.0, 13.0), 'text': ' 대중성으로나 아니면 음악성으로나'}, {'timestamp': (13.0, 14.0), 'text': ' 못 찾는 것 같아요 길을'}, {'timestamp': (14.0, 16.0), 'text': ' 제가 슈퍼 4K에 나온 이유는'}, {'timestamp': (16.0, 18.0), 'text': ' 제 길을 한번 발산해서'}, {'timestamp': (18.0, 22.0), 'text': ' 한국에서 힙합도 많이 발전할 수 있게 기여했으면 좋겠습니다.'}, {'timestamp': (22.0, 23.0), 'text': ' 좀 됐어요?'}, {'timestamp': (23.0, 24.0), 'text': ' 네.'}, {'timestamp': (24.0, 25.0), 'text': ' 해보시죠.'}, {'timestamp': (25.0, 32.0), 'text': \" 체크! 체크! I'm the Korean Thakura's hip-hop home, CHECK! CHECK! I'm not going to do that. I'm not going to do it.\"}, {'timestamp': (32.0, 33.0), 'text': \" I'm not going to do it.\"}, {'timestamp': (33.0, 34.0), 'text': \" I'm not going to do it.\"}, {'timestamp': (34.0, 35.0), 'text': \" I'm not going to do it.\"}, {'timestamp': (35.0, 36.0), 'text': \" I'm not going to do it.\"}, {'timestamp': (36.0, 37.0), 'text': \" I'm not going to do it.\"}, {'timestamp': (37.0, 44.0), 'text': \" I'm not going to do it. I'm not going to do it. I'm not going to do it. uh 아\"}, {'timestamp': (48.0, 49.0), 'text': ' 어디 언어예요?'}, {'timestamp': (49.0, 50.0), 'text': ' 네? 암원같기도 하고 어디 언어예요? 네?'}, {'timestamp': (50.0, 51.0), 'text': ' 앙원같기도 하고 어디 언어예요?'}, {'timestamp': (51.0, 52.0), 'text': ' 그냥 공무집이에요'}, {'timestamp': (52.0, 53.0), 'text': ' 가사는 없는거고'}, {'timestamp': (53.0, 54.0), 'text': ' 가사가 있는거에요'}, {'timestamp': (54.0, 55.0), 'text': ' 가사가 있어요?'}, {'timestamp': (55.0, 56.0), 'text': ' 풀어줘 볼 수 있어요? 천천히요'}, {'timestamp': (56.0, 57.0), 'text': ' 천천히 완전 느리게 해보세요'}, {'timestamp': (57.0, 59.0), 'text': ' 한국어 탁클라스'}, {'timestamp': (59.0, 60.0), 'text': ' 힙합 모범'}, {'timestamp': (60.0, 61.0), 'text': ' 너블라스'}, {'timestamp': (61.0, 62.0), 'text': ' 페이블라스'}, {'timestamp': (62.0, 63.0), 'text': ' 케블라스'}, {'timestamp': (63.0, 64.0), 'text': ' 구조스폴'}, {'timestamp': (64.0, 65.0), 'text': ' danger스'}, {'timestamp': (65.0, 67.0), 'text': ' 난 비틀 비틀 제껴 보니'}, {'timestamp': (67.0, 68.0), 'text': ' 비틀 비틀 제껴 보니'}, {'timestamp': (68.0, 69.0), 'text': ' 비틀 비틀 제껴 보니'}, {'timestamp': (69.0, 71.0), 'text': ' 비틀 비틀 제껴 보니'}, {'timestamp': (71.0, 72.0), 'text': ' 비틀 비틀 제껴 보니'}, {'timestamp': (72.0, 73.0), 'text': ' 비틀 비틀 제껴 보니'}, {'timestamp': (73.0, 74.0), 'text': ' 비틀 비틀 제껴 보니'}, {'timestamp': (74.0, 75.0), 'text': ' 비틀 비틀 제껴 보니'}, {'timestamp': (75.0, 76.0), 'text': ' 비틀 비틀 제껴 보니'}, {'timestamp': (76.0, 77.0), 'text': ' 비틀 비틀 제껴 보니'}, {'timestamp': (77.0, 78.0), 'text': ' 비틀 비틀 제껴 보니'}, {'timestamp': (78.0, 79.0), 'text': ' 비틀 비틀 제껴 보니'}, {'timestamp': (79.0, 80.0), 'text': ' 비틀 비틀 제껴 보니'}, {'timestamp': (80.0, 81.0), 'text': ' 비틀 비틀 제껴 보니'}, {'timestamp': (81.0, 82.0), 'text': ' 비틀 비틀 비틀 제껴 보니'}, {'timestamp': (82.0, 62.0), 'text': \" 한글자막 제공 및 자막 제공 및 협조해 주신 모든 분들께 진심으로 감사드립니다. I don't know. I don't know.\"}, {'timestamp': (62.0, 63.0), 'text': \" I don't know.\"}, {'timestamp': (63.0, 64.0), 'text': \" I don't know.\"}, {'timestamp': (64.0, 65.0), 'text': \" I don't know.\"}, {'timestamp': (65.0, 66.0), 'text': \" I don't know.\"}, {'timestamp': (66.0, 67.0), 'text': \" I don't know.\"}, {'timestamp': (67.0, 68.0), 'text': \" I don't know. I don't know. I don't know. 그러면 잡초마탈파우스 플리지 피해소\"}, {'timestamp': (68.0, 70.0), 'text': ' 하하하하'}, {'timestamp': (70.0, 72.0), 'text': ' 아니 말이 이렇게 있어?'}, {'timestamp': (72.0, 75.0), 'text': ' 아 그니까 그 말을 뭐 이러면서 해가지고 잘 안 들리는 거죠 지금?'}, {'timestamp': (75.0, 76.0), 'text': ' 아 말이 있었다는 게 더 웃겨'}, {'timestamp': (76.0, 77.0), 'text': ' 가산이 있죠?'}, {'timestamp': (77.0, 78.0), 'text': ' 이야...'}, {'timestamp': (78.0, 80.98), 'text': ' 약간 경매장에 온 것 같기도 하고 불합격'}, {'timestamp': (80.98, 81.68), 'text': ' 저도 불합격'}, {'timestamp': (81.68, 82.7), 'text': ' 저도 불합격 드리겠습니다'}]}\n"
     ]
    }
   ],
   "source": [
    "sample = r\"C:\\Users\\user\\Desktop\\KSM\\Music\\Melon_SD\\이성우-01-진또배기-진또배기-192.mp3\"\n",
    "\n",
    "result = pipe(sample)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac4508a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>탑인</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>한국 힙합 제가 생각할 때</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>어준간한 거 같아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>길을 못 찾고 있는 거 같아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>대중성으로나 아니면 음악성으로나</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>76.00</td>\n",
       "      <td>77.00</td>\n",
       "      <td>가산이 있죠?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>77.00</td>\n",
       "      <td>78.00</td>\n",
       "      <td>이야...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>78.00</td>\n",
       "      <td>80.98</td>\n",
       "      <td>약간 경매장에 온 것 같기도 하고 불합격</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>80.98</td>\n",
       "      <td>81.68</td>\n",
       "      <td>저도 불합격</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>81.68</td>\n",
       "      <td>82.70</td>\n",
       "      <td>저도 불합격 드리겠습니다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    start    end                     text\n",
       "0    0.00   2.00                       탑인\n",
       "1    7.00   8.00           한국 힙합 제가 생각할 때\n",
       "2    8.00  10.00               어준간한 거 같아요\n",
       "3   10.00  11.00         길을 못 찾고 있는 거 같아요\n",
       "4   11.00  13.00        대중성으로나 아니면 음악성으로나\n",
       "..    ...    ...                      ...\n",
       "61  76.00  77.00                  가산이 있죠?\n",
       "62  77.00  78.00                    이야...\n",
       "63  78.00  80.98   약간 경매장에 온 것 같기도 하고 불합격\n",
       "64  80.98  81.68                   저도 불합격\n",
       "65  81.68  82.70            저도 불합격 드리겠습니다\n",
       "\n",
       "[66 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_end_text = []\n",
    "\n",
    "for chunk in result[\"chunks\"]:\n",
    "    start = chunk[\"timestamp\"][0]\n",
    "    end = chunk[\"timestamp\"][1]\n",
    "    text = chunk[\"text\"]\n",
    "    start_end_text.append([start, end, text])\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(start_end_text, columns=[\"start\", \"end\", \"text\"])\n",
    "df.to_csv(\"lsy_audio.csv\", index=False, sep=\"|\")\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
